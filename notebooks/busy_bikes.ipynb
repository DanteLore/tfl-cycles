{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "import googlemaps\n",
    "import keyring\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import mplleaflet\n",
    "import pandas as pd\n",
    "import polyline\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "palette = sns.color_palette(\"colorblind\", 20)\n",
    "\n",
    "\n",
    "def to_geo(df, x_field='longitude', y_field='latitude'):\n",
    "    geometry = [Point(xy) for xy in zip(df[x_field], df[y_field])]\n",
    "    return gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"TFL Notebook\")\n",
    "        .config('spark.executor.memory', '8G')\n",
    "        .config('spark.driver.memory', '16G')\n",
    "        .config('spark.driver.maxResultSize', '10G')\n",
    "        .config(\"spark.sql.crossJoin.enabled\", \"true\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "BIKE_POINTS_FILE = \"../data/bike-points.csv\"\n",
    "\n",
    "schema = T.StructType([\n",
    "    T.StructField(\"idx\",       T.IntegerType(), False),\n",
    "    T.StructField(\"id\",        T.IntegerType(), False),\n",
    "    T.StructField(\"name\",      T.StringType(),  False),\n",
    "    T.StructField(\"latitude\",  T.DoubleType(),  False),\n",
    "    T.StructField(\"longitude\", T.DoubleType(),  False),\n",
    "    T.StructField(\"osgb_x\",    T.DoubleType(),  False),\n",
    "    T.StructField(\"osgb_y\",    T.DoubleType(),  False),\n",
    "    T.StructField(\"numdocks\",  T.LongType(),    False),\n",
    "    T.StructField(\"num_bikes\", T.LongType(),    False),\n",
    "    T.StructField(\"num_empty\", T.LongType(),    False)\n",
    "])\n",
    "bike_points = spark.read.csv(BIKE_POINTS_FILE, schema=schema, header='true', mode=\"PERMISSIVE\")\n",
    "bike_points.createOrReplaceTempView(\"bike_points\")\n",
    "\n",
    "trips = spark.read.parquet(\"../data/parquet_trip\")\n",
    "trips.createOrReplaceTempView(\"trips\")\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "    select sum(duration) as duration, count(1) as trip_count, bike_id, start_year, start_month, start_day from trips\n",
    "    group by bike_id, start_year, start_month, start_day\n",
    "    order by trip_count desc\n",
    "\"\"\")\n",
    "\n",
    "df.createOrReplaceTempView(\"busy_bikes\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
